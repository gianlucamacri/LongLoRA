
  3%|█████                                                                                                                                                   | 1/30 [00:02<01:06,  2.28s/it]
 20%|██████████████████████████████▍                                                                                                                         | 2/10 [00:00<00:02,  3.55it/s]



  File "/home/gmacri/tirocinioCameraSummarization/LongLora_fork/LongLoRA/supervised-fine-tune-qlora.py", line 389, in <module>██████████████████████████████| 10/10 [00:05<00:00,  1.52it/s]
    train()
  File "/home/gmacri/tirocinioCameraSummarization/LongLora_fork/LongLoRA/supervised-fine-tune-qlora.py", line 383, in train
    trainer.train()
  File "/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/transformers/trainer.py", line 1984, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/transformers/trainer.py", line 2328, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/transformers/trainer.py", line 3066, in evaluate
    output = eval_loop(
  File "/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/transformers/trainer.py", line 3359, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
  File "/home/gmacri/tirocinioCameraSummarization/LongLora_fork/LongLoRA/supervised-fine-tune-qlora.py", line 233, in <lambda>
    compute_metrics = lambda x: compute_metrics_hf(eval_pred=x, metrics=metrics, tokenizer=tokenizer)
  File "/home/gmacri/tirocinioCameraSummarization/LongLora_fork/LongLoRA/supervised-fine-tune-qlora.py", line 240, in compute_metrics_hf
    y = tokenizer.batch_decode(y)
  File "/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3698, in batch_decode
    return [
  File "/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3699, in <listcomp>
    self.decode(
  File "/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3738, in decode
    return self._decode(
  File "/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py", line 625, in _decode
    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)
OverflowError: out of range integral type conversion attempted