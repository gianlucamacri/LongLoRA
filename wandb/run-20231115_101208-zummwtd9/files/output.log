  0%|                                                                                                                                                                 | 0/2 [00:00<?, ?it/s]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 50%|████████████████████████████████████████████████████████████████████████████▌                                                                            | 1/2 [00:34<00:34, 34.15s/it]
{'loss': 5.1438, 'learning_rate': 2e-05, 'epoch': 0.02}



 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:08<00:01,  1.85s/it]

  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 4.825, 'learning_rate': 2e-05, 'epoch': 0.04}
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:23<00:00, 43.05s/it]




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:01,  1.89s/it]
{'eval_loss': 5.817183971405029, 'eval_runtime': 15.377, 'eval_samples_per_second': 0.39, 'eval_steps_per_second': 0.39, 'epoch': 0.04}
/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:67: UserWarning: Merge lora module to 8-bit linear may get different generations due to rounding errors.
  warnings.warn(