  0%|                                                                                                                                                               | 0/300 [00:00<?, ?it/s]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
  0%|▍                                                                                                                                                  | 1/300 [03:38<18:08:22, 218.40s/it]

  1%|▉                                                                                                                                                  | 2/300 [07:29<18:40:45, 225.66s/it]

  1%|█▍                                                                                                                                                 | 3/300 [11:06<18:18:05, 221.84s/it]

  1%|█▉                                                                                                                                                 | 4/300 [14:19<17:18:36, 210.53s/it]

  2%|██▍                                                                                                                                                | 5/300 [17:49<17:13:43, 210.25s/it]

  2%|██▉                                                                                                                                                | 6/300 [21:10<16:54:46, 207.10s/it]
{'loss': 4.9631, 'learning_rate': 2e-05, 'epoch': 0.99}





 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.04s/it]
  2%|██▉                                                                                                                                                | 6/300 [21:32<16:54:46, 207.10s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 4.4075, 'learning_rate': 2e-05, 'epoch': 1.15}
  2%|███▍                                                                                                                                               | 7/300 [25:26<18:09:43, 223.15s/it]

  3%|███▉                                                                                                                                               | 8/300 [29:04<17:58:13, 221.55s/it]

  3%|████▍                                                                                                                                              | 9/300 [32:47<17:56:32, 221.97s/it]

  3%|████▊                                                                                                                                             | 10/300 [36:23<17:43:30, 220.04s/it]

  4%|█████▎                                                                                                                                            | 11/300 [39:38<17:02:47, 212.34s/it]

  4%|█████▊                                                                                                                                            | 12/300 [43:13<17:03:38, 213.26s/it]



 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.05s/it]

  4%|█████▊                                                                                                                                            | 12/300 [43:52<17:03:38, 213.26s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 4.6776, 'learning_rate': 2e-05, 'epoch': 2.14}

  5%|██████▊                                                                                                                                           | 14/300 [50:13<16:42:11, 210.25s/it]
{'loss': 4.7603, 'learning_rate': 2e-05, 'epoch': 2.31}

  5%|███████▎                                                                                                                                          | 15/300 [53:52<16:51:17, 212.90s/it]

  5%|███████▊                                                                                                                                          | 16/300 [57:56<17:32:31, 222.36s/it]

  6%|████████▏                                                                                                                                       | 17/300 [1:01:09<16:46:39, 213.42s/it]

  6%|████████▋                                                                                                                                       | 18/300 [1:04:41<16:41:20, 213.05s/it]



 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.09s/it]

  6%|████████▋                                                                                                                                       | 18/300 [1:05:59<16:41:20, 213.05s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 4.5423, 'learning_rate': 2e-05, 'epoch': 3.13}

  7%|█████████▌                                                                                                                                      | 20/300 [1:12:48<17:48:38, 228.99s/it]
{'loss': 3.6669, 'learning_rate': 2e-05, 'epoch': 3.3}

  7%|██████████                                                                                                                                      | 21/300 [1:16:24<17:26:14, 225.00s/it]


  8%|███████████                                                                                                                                     | 23/300 [1:23:35<17:00:05, 220.96s/it]

  8%|███████████▌                                                                                                                                    | 24/300 [1:27:12<16:50:15, 219.62s/it]
{'loss': 3.5895, 'learning_rate': 2e-05, 'epoch': 3.96}




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.04s/it]
  8%|███████████▌                                                                                                                                    | 24/300 [1:28:11<16:50:15, 219.62s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 3.5364, 'learning_rate': 2e-05, 'epoch': 4.12}

  9%|████████████▍                                                                                                                                   | 26/300 [1:34:22<16:29:35, 216.70s/it]
{'loss': 3.5641, 'learning_rate': 2e-05, 'epoch': 4.29}


  9%|█████████████▍                                                                                                                                  | 28/300 [1:41:26<16:04:01, 212.65s/it]

 10%|█████████████▉                                                                                                                                  | 29/300 [1:45:21<16:30:34, 219.32s/it]

 10%|██████████████▍                                                                                                                                 | 30/300 [1:48:47<16:09:12, 215.38s/it]
{'loss': 3.3566, 'learning_rate': 2e-05, 'epoch': 4.95}





100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:13<00:00,  2.54s/it]

  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 3.1974, 'learning_rate': 2e-05, 'epoch': 5.11}
 10%|██████████████▉                                                                                                                                 | 31/300 [1:53:02<16:58:07, 227.09s/it]

 11%|███████████████▎                                                                                                                                | 32/300 [1:56:12<16:05:23, 216.13s/it]

 11%|███████████████▊                                                                                                                                | 33/300 [2:00:06<16:25:39, 221.50s/it]

 11%|████████████████▎                                                                                                                               | 34/300 [2:03:24<15:50:47, 214.46s/it]


 12%|█████████████████▎                                                                                                                              | 36/300 [2:11:19<16:31:33, 225.35s/it]
{'loss': 2.9548, 'learning_rate': 2e-05, 'epoch': 5.94}




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.03s/it]

 12%|█████████████████▎                                                                                                                              | 36/300 [2:12:44<16:31:33, 225.35s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 3.2132, 'learning_rate': 2e-05, 'epoch': 6.1}
 12%|█████████████████▊                                                                                                                              | 37/300 [2:14:55<16:16:30, 222.78s/it]

 13%|██████████████████▏                                                                                                                             | 38/300 [2:18:18<15:46:23, 216.73s/it]


 13%|███████████████████▏                                                                                                                            | 40/300 [2:25:30<15:35:22, 215.86s/it]
{'loss': 3.2419, 'learning_rate': 2e-05, 'epoch': 6.6}

 14%|███████████████████▋                                                                                                                            | 41/300 [2:29:08<15:35:29, 216.72s/it]

 14%|████████████████████▏                                                                                                                           | 42/300 [2:33:09<16:02:37, 223.87s/it]




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.02s/it]

 14%|████████████████████▏                                                                                                                           | 42/300 [2:35:05<16:02:37, 223.87s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 2.9858, 'learning_rate': 2e-05, 'epoch': 7.09}

 15%|█████████████████████                                                                                                                           | 44/300 [2:40:18<15:24:37, 216.71s/it]
{'loss': 2.9234, 'learning_rate': 2e-05, 'epoch': 7.26}

 15%|█████████████████████▌                                                                                                                          | 45/300 [2:43:42<15:04:25, 212.81s/it]


 16%|██████████████████████▌                                                                                                                         | 47/300 [2:51:04<15:13:36, 216.66s/it]

 16%|███████████████████████                                                                                                                         | 48/300 [2:55:03<15:38:55, 223.55s/it]
{'loss': 2.923, 'learning_rate': 2e-05, 'epoch': 7.92}





 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.01s/it]
 16%|███████████████████████                                                                                                                         | 48/300 [2:57:13<15:38:55, 223.55s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 16%|███████████████████████▌                                                                                                                        | 49/300 [2:59:22<16:19:04, 234.04s/it]
{'loss': 2.6677, 'learning_rate': 2e-05, 'epoch': 8.08}


 17%|████████████████████████▍                                                                                                                       | 51/300 [3:05:57<14:54:36, 215.57s/it]

 17%|████████████████████████▉                                                                                                                       | 52/300 [3:10:15<15:43:47, 228.34s/it]

 18%|█████████████████████████▍                                                                                                                      | 53/300 [3:13:55<15:29:18, 225.74s/it]

 18%|█████████████████████████▉                                                                                                                      | 54/300 [3:17:21<15:02:16, 220.07s/it]
{'loss': 2.5389, 'learning_rate': 2e-05, 'epoch': 8.91}




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.09s/it]

  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 2.7442, 'learning_rate': 2e-05, 'epoch': 9.07}

 19%|██████████████████████████▉                                                                                                                     | 56/300 [3:24:42<14:49:51, 218.82s/it]

 19%|███████████████████████████▎                                                                                                                    | 57/300 [3:28:01<14:22:40, 213.00s/it]

 19%|███████████████████████████▊                                                                                                                    | 58/300 [3:31:44<14:30:57, 215.94s/it]

 20%|████████████████████████████▎                                                                                                                   | 59/300 [3:36:02<15:17:46, 228.49s/it]

 20%|████████████████████████████▊                                                                                                                   | 60/300 [3:39:28<14:47:29, 221.87s/it]
{'loss': 2.4513, 'learning_rate': 2e-05, 'epoch': 9.9}





 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.01s/it]
 20%|████████████████████████████▊                                                                                                                   | 60/300 [3:41:53<14:47:29, 221.87s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 20%|█████████████████████████████▎                                                                                                                  | 61/300 [3:43:28<15:04:52, 227.16s/it]

 21%|█████████████████████████████▊                                                                                                                  | 62/300 [3:46:55<14:37:35, 221.24s/it]

 21%|██████████████████████████████▏                                                                                                                 | 63/300 [3:50:20<14:14:03, 216.22s/it]

 21%|██████████████████████████████▋                                                                                                                 | 64/300 [3:54:26<14:46:30, 225.38s/it]

 22%|███████████████████████████████▏                                                                                                                | 65/300 [3:57:59<14:28:03, 221.63s/it]

 22%|███████████████████████████████▋                                                                                                                | 66/300 [4:01:30<14:11:14, 218.27s/it]
{'loss': 2.2755, 'learning_rate': 2e-05, 'epoch': 10.89}





 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.05s/it]
 22%|███████████████████████████████▋                                                                                                                | 66/300 [4:04:21<14:11:14, 218.27s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 22%|████████████████████████████████▏                                                                                                               | 67/300 [4:05:12<14:12:22, 219.50s/it]

 23%|████████████████████████████████▋                                                                                                               | 68/300 [4:09:23<14:44:32, 228.76s/it]
{'loss': 2.3038, 'learning_rate': 2e-05, 'epoch': 11.22}

 23%|█████████████████████████████████                                                                                                               | 69/300 [4:12:49<14:15:32, 222.22s/it]

 23%|█████████████████████████████████▌                                                                                                              | 70/300 [4:16:32<14:12:36, 222.42s/it]

 24%|██████████████████████████████████                                                                                                              | 71/300 [4:20:10<14:02:52, 220.84s/it]

 24%|██████████████████████████████████▌                                                                                                             | 72/300 [4:23:50<13:58:53, 220.76s/it]





100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:13<00:00,  2.58s/it]

  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 2.1709, 'learning_rate': 2e-05, 'epoch': 12.04}
 24%|███████████████████████████████████                                                                                                             | 73/300 [4:27:51<14:18:21, 226.88s/it]

 25%|███████████████████████████████████▌                                                                                                            | 74/300 [4:31:12<13:44:38, 218.93s/it]

 25%|████████████████████████████████████                                                                                                            | 75/300 [4:35:01<13:52:37, 222.04s/it]


 26%|████████████████████████████████████▉                                                                                                           | 77/300 [4:42:42<14:01:05, 226.30s/it]
{'loss': 1.5516, 'learning_rate': 2e-05, 'epoch': 12.7}

 26%|█████████████████████████████████████▍                                                                                                          | 78/300 [4:46:41<14:10:53, 229.97s/it]




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.08s/it]
 26%|█████████████████████████████████████▍                                                                                                          | 78/300 [4:49:22<14:10:53, 229.97s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.7017, 'learning_rate': 2e-05, 'epoch': 13.03}
 26%|█████████████████████████████████████▉                                                                                                          | 79/300 [4:49:53<13:25:45, 218.76s/it]

 27%|██████████████████████████████████████▍                                                                                                         | 80/300 [4:53:40<13:31:01, 221.19s/it]

 27%|██████████████████████████████████████▉                                                                                                         | 81/300 [4:57:20<13:25:48, 220.77s/it]


 28%|███████████████████████████████████████▊                                                                                                        | 83/300 [5:05:07<13:45:49, 228.34s/it]

 28%|████████████████████████████████████████▎                                                                                                       | 84/300 [5:08:46<13:30:57, 225.27s/it]
{'loss': 1.5132, 'learning_rate': 2e-05, 'epoch': 13.86}




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.02s/it]

 28%|████████████████████████████████████████▎                                                                                                       | 84/300 [5:12:02<13:30:57, 225.27s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.599, 'learning_rate': 2e-05, 'epoch': 14.02}
 28%|████████████████████████████████████████▊                                                                                                       | 85/300 [5:12:47<13:44:43, 230.15s/it]

 29%|█████████████████████████████████████████▎                                                                                                      | 86/300 [5:16:27<13:30:22, 227.21s/it]

 29%|█████████████████████████████████████████▊                                                                                                      | 87/300 [5:20:07<13:18:21, 224.89s/it]

 29%|██████████████████████████████████████████▏                                                                                                     | 88/300 [5:23:28<12:49:36, 217.81s/it]

 30%|██████████████████████████████████████████▋                                                                                                     | 89/300 [5:27:02<12:42:08, 216.72s/it]

 30%|███████████████████████████████████████████▏                                                                                                    | 90/300 [5:31:12<13:13:25, 226.69s/it]




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.02s/it]
 30%|███████████████████████████████████████████▏                                                                                                    | 90/300 [5:34:27<13:13:25, 226.69s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.5945, 'learning_rate': 2e-05, 'epoch': 15.01}
 30%|███████████████████████████████████████████▋                                                                                                    | 91/300 [5:34:47<12:57:05, 223.09s/it]

 31%|████████████████████████████████████████████▏                                                                                                   | 92/300 [5:38:49<13:13:00, 228.75s/it]

 31%|████████████████████████████████████████████▋                                                                                                   | 93/300 [5:42:59<13:31:39, 235.26s/it]


 32%|█████████████████████████████████████████████▌                                                                                                  | 95/300 [5:49:29<12:03:49, 211.85s/it]
{'loss': 1.5123, 'learning_rate': 2e-05, 'epoch': 15.67}


 32%|██████████████████████████████████████████████▌                                                                                                 | 97/300 [5:56:45<12:07:44, 215.09s/it]
{'loss': 1.5797, 'learning_rate': 2e-05, 'epoch': 16.0}




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.05s/it]

 32%|██████████████████████████████████████████████▌                                                                                                 | 97/300 [5:57:02<12:07:44, 215.09s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 33%|███████████████████████████████████████████████                                                                                                 | 98/300 [6:00:38<12:21:39, 220.29s/it]

 33%|███████████████████████████████████████████████▌                                                                                                | 99/300 [6:03:50<11:49:27, 211.78s/it]
{'loss': 1.2253, 'learning_rate': 2e-05, 'epoch': 16.33}

 33%|███████████████████████████████████████████████▋                                                                                               | 100/300 [6:07:29<11:53:26, 214.03s/it]

 34%|████████████████████████████████████████████████▏                                                                                              | 101/300 [6:12:06<12:52:08, 232.81s/it]


 34%|█████████████████████████████████████████████████                                                                                              | 103/300 [6:19:11<12:07:52, 221.69s/it]
{'loss': 1.3507, 'learning_rate': 2e-05, 'epoch': 16.99}




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:01,  2.00s/it]

 34%|█████████████████████████████████████████████████                                                                                              | 103/300 [6:19:40<12:07:52, 221.69s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 35%|█████████████████████████████████████████████████▌                                                                                             | 104/300 [6:23:21<12:31:48, 230.15s/it]

 35%|██████████████████████████████████████████████████                                                                                             | 105/300 [6:26:57<12:14:54, 226.12s/it]
{'loss': 1.2741, 'learning_rate': 2e-05, 'epoch': 17.32}

 35%|██████████████████████████████████████████████████▌                                                                                            | 106/300 [6:30:16<11:44:47, 217.98s/it]


 36%|███████████████████████████████████████████████████▍                                                                                           | 108/300 [6:37:40<11:51:00, 222.19s/it]

 36%|███████████████████████████████████████████████████▉                                                                                           | 109/300 [6:41:12<11:37:42, 219.18s/it]
{'loss': 1.0174, 'learning_rate': 2e-05, 'epoch': 17.98}




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:01,  2.00s/it]
 36%|███████████████████████████████████████████████████▉                                                                                           | 109/300 [6:42:10<11:37:42, 219.18s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.3515, 'learning_rate': 2e-05, 'epoch': 18.14}
 37%|████████████████████████████████████████████████████▍                                                                                          | 110/300 [6:45:01<11:43:30, 222.16s/it]

 37%|████████████████████████████████████████████████████▉                                                                                          | 111/300 [6:48:39<11:35:44, 220.87s/it]


 38%|█████████████████████████████████████████████████████▊                                                                                         | 113/300 [6:56:36<11:58:23, 230.50s/it]

 38%|██████████████████████████████████████████████████████▎                                                                                        | 114/300 [6:59:52<11:22:46, 220.25s/it]

 38%|██████████████████████████████████████████████████████▊                                                                                        | 115/300 [7:03:49<11:34:29, 225.24s/it]
{'loss': 1.2525, 'learning_rate': 2e-05, 'epoch': 18.97}





 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.06s/it]
 38%|██████████████████████████████████████████████████████▊                                                                                        | 115/300 [7:04:39<11:34:29, 225.24s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 39%|███████████████████████████████████████████████████████▎                                                                                       | 116/300 [7:07:33<11:29:10, 224.73s/it]

 39%|███████████████████████████████████████████████████████▊                                                                                       | 117/300 [7:11:06<11:14:56, 221.29s/it]

 39%|████████████████████████████████████████████████████████▏                                                                                      | 118/300 [7:15:18<11:39:24, 230.57s/it]
{'loss': 1.3366, 'learning_rate': 2e-05, 'epoch': 19.46}


 40%|█████████████████████████████████████████████████████████▏                                                                                     | 120/300 [7:22:39<11:12:20, 224.12s/it]
{'loss': 1.0812, 'learning_rate': 2e-05, 'epoch': 19.79}

 40%|█████████████████████████████████████████████████████████▋                                                                                     | 121/300 [7:26:02<10:50:18, 217.98s/it]





 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.02s/it]
 40%|█████████████████████████████████████████████████████████▋                                                                                     | 121/300 [7:27:11<10:50:18, 217.98s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.2438, 'learning_rate': 2e-05, 'epoch': 20.12}

 41%|██████████████████████████████████████████████████████████▋                                                                                    | 123/300 [7:33:54<11:06:05, 225.79s/it]
{'loss': 1.2522, 'learning_rate': 2e-05, 'epoch': 20.29}


 42%|███████████████████████████████████████████████████████████▌                                                                                   | 125/300 [7:41:52<11:14:22, 231.21s/it]

 42%|████████████████████████████████████████████████████████████                                                                                   | 126/300 [7:44:59<10:31:51, 217.88s/it]
{'loss': 0.9236, 'learning_rate': 2e-05, 'epoch': 20.78}

 42%|████████████████████████████████████████████████████████████▌                                                                                  | 127/300 [7:48:30<10:22:04, 215.75s/it]





 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.05s/it]
 42%|████████████████████████████████████████████████████████████▌                                                                                  | 127/300 [7:49:40<10:22:04, 215.75s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 43%|█████████████████████████████████████████████████████████████                                                                                  | 128/300 [7:52:13<10:24:40, 217.91s/it]

 43%|█████████████████████████████████████████████████████████████▍                                                                                 | 129/300 [7:55:39<10:11:09, 214.44s/it]

 43%|█████████████████████████████████████████████████████████████▉                                                                                 | 130/300 [7:59:48<10:37:06, 224.86s/it]

 44%|██████████████████████████████████████████████████████████████▍                                                                                | 131/300 [8:03:10<10:14:14, 218.07s/it]

 44%|██████████████████████████████████████████████████████████████▉                                                                                | 132/300 [8:06:59<10:19:22, 221.20s/it]

 44%|███████████████████████████████████████████████████████████████▍                                                                               | 133/300 [8:10:38<10:14:04, 220.63s/it]
{'loss': 1.1584, 'learning_rate': 2e-05, 'epoch': 21.94}





 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.03s/it]
 44%|███████████████████████████████████████████████████████████████▍                                                                               | 133/300 [8:12:17<10:14:04, 220.63s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 0.6333, 'learning_rate': 2e-05, 'epoch': 22.1}
 45%|████████████████████████████████████████████████████████████████▎                                                                               | 134/300 [8:14:02<9:56:13, 215.50s/it]


 45%|████████████████████████████████████████████████████████████████▊                                                                              | 136/300 [8:22:42<10:52:33, 238.74s/it]
{'loss': 1.0416, 'learning_rate': 2e-05, 'epoch': 22.43}

 46%|█████████████████████████████████████████████████████████████████▎                                                                             | 137/300 [8:25:42<10:00:27, 221.02s/it]

 46%|██████████████████████████████████████████████████████████████████▏                                                                             | 138/300 [8:28:53<9:32:22, 211.99s/it]

 46%|██████████████████████████████████████████████████████████████████▋                                                                             | 139/300 [8:32:38<9:39:38, 216.01s/it]




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.04s/it]

 46%|██████████████████████████████████████████████████████████████████▋                                                                             | 139/300 [8:34:40<9:39:38, 216.01s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.1339, 'learning_rate': 2e-05, 'epoch': 23.09}
 47%|███████████████████████████████████████████████████████████████████▏                                                                            | 140/300 [8:36:44<9:59:36, 224.85s/it]

 47%|███████████████████████████████████████████████████████████████████▋                                                                            | 141/300 [8:40:32<9:58:41, 225.92s/it]

 47%|████████████████████████████████████████████████████████████████████▏                                                                           | 142/300 [8:44:02<9:42:03, 221.03s/it]

 48%|████████████████████████████████████████████████████████████████████▋                                                                           | 143/300 [8:47:21<9:21:26, 214.56s/it]

 48%|█████████████████████████████████████████████████████████████████████                                                                           | 144/300 [8:50:46<9:09:58, 211.53s/it]

 48%|█████████████████████████████████████████████████████████████████████▌                                                                          | 145/300 [8:54:40<9:24:03, 218.34s/it]




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.08s/it]

 48%|█████████████████████████████████████████████████████████████████████▌                                                                          | 145/300 [8:57:07<9:24:03, 218.34s/it]/home/gmacri/anaconda3/envs/LongLora/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 0.7778, 'learning_rate': 2e-05, 'epoch': 24.08}
 49%|█████████████████████████████████████████████████████████████████████▌                                                                         | 146/300 [8:59:12<10:01:41, 234.42s/it]

 49%|██████████████████████████████████████████████████████████████████████                                                                         | 147/300 [9:03:29<10:14:52, 241.13s/it]

 49%|███████████████████████████████████████████████████████████████████████                                                                         | 148/300 [9:06:51<9:41:09, 229.40s/it]

 50%|███████████████████████████████████████████████████████████████████████▌                                                                        | 149/300 [9:10:14<9:17:35, 221.56s/it]


 50%|████████████████████████████████████████████████████████████████████████▍                                                                       | 151/300 [9:17:28<9:07:36, 220.51s/it]
{'loss': 1.1062, 'learning_rate': 2e-05, 'epoch': 24.91}




 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 5/6 [00:09<00:02,  2.01s/it]

{'eval_loss': 0.4200754165649414, 'eval_runtime': 16.3297, 'eval_samples_per_second': 0.367, 'eval_steps_per_second': 0.367, 'epoch': 24.91}
{'train_runtime': 33573.7383, 'train_samples_per_second': 0.144, 'train_steps_per_second': 0.009, 'train_loss': 2.2845909072468613, 'epoch': 24.91}